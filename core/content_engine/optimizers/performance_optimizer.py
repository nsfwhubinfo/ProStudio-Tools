#!/usr/bin/env python3
"""
Performance Optimizer
=====================

Optimizes content generation for <1s performance using caching,
parallel processing, and intelligent precomputation.
"""

import time
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from functools import lru_cache
import hashlib
import json
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass

from ..base_classes import ContentOptimizer
from ..content_types import ContentPiece, ContentType, Platform, OptimizationMetrics


@dataclass
class PerformanceMetrics:
    """Performance tracking metrics"""
    generation_time: float
    optimization_time: float
    total_time: float
    cache_hits: int
    cache_misses: int
    parallel_tasks: int


class CacheManager:
    """Manages intelligent caching for content generation"""
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.max_size = max_size
        self.hits = 0
        self.misses = 0
        self.lock = threading.Lock()
    
    def _generate_key(self, concept: str, platform: str, content_type: str) -> str:
        """Generate cache key from parameters"""
        data = f"{concept}:{platform}:{content_type}"
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(self, concept: str, platform: str, content_type: str) -> Optional[Dict[str, Any]]:
        """Get cached data if available"""
        key = self._generate_key(concept, platform, content_type)
        
        with self.lock:
            if key in self.cache:
                self.hits += 1
                # Update access time
                self.cache[key]['last_access'] = time.time()
                return self.cache[key]['data']
            else:
                self.misses += 1
                return None
    
    def set(self, concept: str, platform: str, content_type: str, data: Dict[str, Any]):
        """Cache data with LRU eviction"""
        key = self._generate_key(concept, platform, content_type)
        
        with self.lock:
            # Evict oldest if at capacity
            if len(self.cache) >= self.max_size:
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k]['last_access'])
                del self.cache[oldest_key]
            
            self.cache[key] = {
                'data': data,
                'created': time.time(),
                'last_access': time.time()
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        with self.lock:
            total_requests = self.hits + self.misses
            hit_rate = self.hits / total_requests if total_requests > 0 else 0
            
            return {
                'hits': self.hits,
                'misses': self.misses,
                'hit_rate': hit_rate,
                'size': len(self.cache),
                'max_size': self.max_size
            }


class PerformanceOptimizer(ContentOptimizer):
    """
    Optimizes content generation for maximum speed while maintaining quality
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or self._default_config()
        self.cache_manager = CacheManager(max_size=self.config['cache_size'])
        self.template_cache = {}
        self.trending_data_cache = {}
        self.last_trending_update = 0
        self.executor = ThreadPoolExecutor(max_workers=self.config['max_workers'])
        
        # Precompute common patterns
        self._precompute_patterns()
    
    def _default_config(self) -> Dict[str, Any]:
        """Default performance configuration"""
        return {
            'cache_size': 1000,
            'max_workers': 4,
            'enable_caching': True,
            'enable_parallel': True,
            'trending_cache_ttl': 3600,  # 1 hour
            'precompute_templates': True,
            'batch_optimization': True
        }
    
    def _precompute_patterns(self):
        """Precompute common patterns for faster generation"""
        # Precompute golden ratio points
        self.golden_points = {
            15: [5, 9, 14],      # 15 second video
            30: [11, 18, 27],    # 30 second video
            60: [23, 37, 55],    # 60 second video
            600: [229, 371, 550] # 10 minute video
        }
        
        # Precompute engagement patterns
        self.engagement_patterns = {
            'high_energy': np.array([0.9, 0.85, 0.8, 0.9, 0.85]),
            'steady': np.array([0.8, 0.8, 0.8, 0.8, 0.8]),
            'building': np.array([0.7, 0.75, 0.8, 0.85, 0.9])
        }
        
        # Precompute hashtag sets
        self.hashtag_templates = {
            'viral': ['#fyp', '#viral', '#trending', '#foryou'],
            'educational': ['#learn', '#education', '#howto', '#tutorial'],
            'entertainment': ['#funny', '#comedy', '#entertainment', '#lol']
        }
    
    def analyze(self, content: ContentPiece) -> OptimizationMetrics:
        """Fast analysis using cached patterns"""
        start_time = time.time()
        
        # Check cache first
        if self.config['enable_caching']:
            cached = self.cache_manager.get(
                str(content.id),
                content.platform.value,
                content.content_type.value
            )
            if cached and 'metrics' in cached:
                return OptimizationMetrics(**cached['metrics'])
        
        # Fast metric calculation using precomputed patterns
        metrics = self._fast_analyze(content)
        
        # Cache results
        if self.config['enable_caching']:
            self.cache_manager.set(
                str(content.id),
                content.platform.value,
                content.content_type.value,
                {'metrics': vars(metrics)}
            )
        
        analysis_time = time.time() - start_time
        content.metadata.tags.append(f"analysis_time:{analysis_time:.3f}s")
        
        return metrics
    
    def enhance(self, content: ContentPiece, target_metrics: OptimizationMetrics) -> ContentPiece:
        """Fast enhancement using parallel processing"""
        start_time = time.time()
        
        if self.config['enable_parallel']:
            # Parallel enhancement tasks
            futures = []
            
            # Submit parallel tasks
            futures.append(
                self.executor.submit(self._enhance_engagement, content, target_metrics)
            )
            futures.append(
                self.executor.submit(self._enhance_virality, content, target_metrics)
            )
            futures.append(
                self.executor.submit(self._enhance_platform_optimization, content)
            )
            
            # Collect results
            enhancements = []
            for future in as_completed(futures):
                enhancements.append(future.result())
            
            # Apply all enhancements
            for enhancement in enhancements:
                content = self._apply_enhancement(content, enhancement)
        else:
            # Sequential enhancement
            content = self._enhance_engagement(content, target_metrics)
            content = self._enhance_virality(content, target_metrics)
            content = self._enhance_platform_optimization(content)
        
        enhancement_time = time.time() - start_time
        content.metadata.tags.append(f"enhancement_time:{enhancement_time:.3f}s")
        
        return content
    
    def optimize_batch(self, contents: List[ContentPiece]) -> List[ContentPiece]:
        """Optimize multiple content pieces in parallel"""
        if not self.config['batch_optimization']:
            # Fallback to sequential
            return [self.enhance(c, self.analyze(c)) for c in contents]
        
        start_time = time.time()
        
        # Submit all content for parallel processing
        future_to_content = {}
        for content in contents:
            future = self.executor.submit(self._optimize_single, content)
            future_to_content[future] = content
        
        # Collect optimized content
        optimized = []
        for future in as_completed(future_to_content):
            optimized_content = future.result()
            optimized.append(optimized_content)
        
        batch_time = time.time() - start_time
        avg_time = batch_time / len(contents) if contents else 0
        
        print(f"‚ö° Batch optimization complete: {len(contents)} pieces in {batch_time:.2f}s")
        print(f"   Average: {avg_time:.3f}s per piece")
        
        return optimized
    
    def _fast_analyze(self, content: ContentPiece) -> OptimizationMetrics:
        """Fast metric analysis using precomputed patterns"""
        metrics = OptimizationMetrics()
        
        # Use platform-specific quick calculations
        platform_multipliers = {
            Platform.TIKTOK: 1.3,
            Platform.INSTAGRAM: 1.2,
            Platform.YOUTUBE: 1.1
        }
        
        base_engagement = 70
        platform_mult = platform_multipliers.get(content.platform, 1.0)
        
        # Quick consciousness scoring
        consciousness_score = (
            content.consciousness.coherence_level * 0.5 +
            content.consciousness.phi_resonance * 0.3 +
            (0.2 if content.consciousness.fractal_dimension > 1.5 else 0.1)
        )
        
        metrics.predicted_engagement = base_engagement * platform_mult * (1 + consciousness_score)
        metrics.viral_coefficient = 1.0 + consciousness_score
        metrics.roi_estimate = metrics.predicted_engagement * 10
        metrics.platform_optimization_score = min(consciousness_score * 1.5, 1.0)
        
        return metrics
    
    def _enhance_engagement(self, 
                          content: ContentPiece,
                          target_metrics: OptimizationMetrics) -> Dict[str, Any]:
        """Enhance engagement metrics"""
        enhancements = {
            'type': 'engagement',
            'modifications': {}
        }
        
        # Quick engagement boosters
        if content.consciousness.coherence_level < 0.8:
            enhancements['modifications']['coherence_boost'] = 0.1
        
        if content.consciousness.phi_resonance < 0.7:
            enhancements['modifications']['phi_alignment'] = True
        
        # Platform-specific quick wins
        if content.platform == Platform.TIKTOK:
            enhancements['modifications']['add_trending_sound'] = True
        elif content.platform == Platform.INSTAGRAM:
            enhancements['modifications']['optimize_first_frame'] = True
        elif content.platform == Platform.YOUTUBE:
            enhancements['modifications']['add_timestamps'] = True
        
        return enhancements
    
    def _enhance_virality(self,
                         content: ContentPiece,
                         target_metrics: OptimizationMetrics) -> Dict[str, Any]:
        """Enhance viral potential"""
        enhancements = {
            'type': 'virality',
            'modifications': {}
        }
        
        # Quick viral elements
        if len(content.metadata.hashtags) < 5:
            # Use precomputed hashtag templates
            template_key = 'viral'
            if hasattr(content, 'raw_content') and content.raw_content:
                if 'strategy' in content.raw_content:
                    strategy_type = content.raw_content.get('strategy', {}).get('type', '')
                    if 'educational' in strategy_type:
                        template_key = 'educational'
                    elif 'entertainment' in strategy_type:
                        template_key = 'entertainment'
            
            enhancements['modifications']['add_hashtags'] = self.hashtag_templates[template_key]
        
        # Quick hook optimization
        enhancements['modifications']['strengthen_hook'] = True
        
        return enhancements
    
    def _enhance_platform_optimization(self, content: ContentPiece) -> Dict[str, Any]:
        """Platform-specific optimization"""
        enhancements = {
            'type': 'platform',
            'modifications': {}
        }
        
        # Use precomputed golden points
        if hasattr(content, 'raw_content') and content.raw_content:
            duration = content.raw_content.get('duration', 30)
            
            # Find closest precomputed duration
            closest_duration = min(self.golden_points.keys(), 
                                 key=lambda x: abs(x - duration))
            
            if closest_duration in self.golden_points:
                enhancements['modifications']['golden_points'] = self.golden_points[closest_duration]
        
        return enhancements
    
    def _apply_enhancement(self, content: ContentPiece, enhancement: Dict[str, Any]) -> ContentPiece:
        """Apply enhancement to content"""
        modifications = enhancement.get('modifications', {})
        
        for key, value in modifications.items():
            if key == 'coherence_boost':
                content.consciousness.coherence_level = min(
                    content.consciousness.coherence_level + value, 1.0
                )
            elif key == 'phi_alignment':
                content.consciousness.phi_resonance = 0.618
                content.consciousness.fractal_dimension = 1.618
            elif key == 'add_hashtags' and isinstance(value, list):
                content.metadata.hashtags.extend(value)
                content.metadata.hashtags = list(set(content.metadata.hashtags))[:30]
            elif key == 'golden_points' and hasattr(content, 'raw_content'):
                if 'structure' in content.raw_content:
                    content.raw_content['structure']['golden_points'] = value
        
        return content
    
    def _optimize_single(self, content: ContentPiece) -> ContentPiece:
        """Optimize single content piece"""
        metrics = self.analyze(content)
        return self.enhance(content, metrics)
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics"""
        cache_stats = self.cache_manager.get_stats()
        
        return {
            'cache': cache_stats,
            'threading': {
                'max_workers': self.config['max_workers'],
                'active_threads': self.executor._threads.__len__() if hasattr(self.executor, '_threads') else 0
            },
            'optimizations': {
                'caching_enabled': self.config['enable_caching'],
                'parallel_enabled': self.config['enable_parallel'],
                'batch_enabled': self.config['batch_optimization']
            }
        }
    
    @lru_cache(maxsize=128)
    def _cached_pattern_match(self, pattern_key: str, duration: int) -> List[int]:
        """Cached pattern matching for common durations"""
        if pattern_key == 'golden_ratio':
            phi = 1.618
            points = []
            point = duration / phi
            while point > 1:
                points.append(int(point))
                point = point / phi
            return sorted(points)
        return []
    
    def warmup_cache(self):
        """Warmup cache with common patterns"""
        print("üî• Warming up performance cache...")
        
        common_concepts = [
            "viral content", "how to", "tutorial", "story time",
            "transformation", "day in life", "reaction", "challenge"
        ]
        
        platforms = [Platform.TIKTOK, Platform.INSTAGRAM, Platform.YOUTUBE]
        content_types = [ContentType.VIDEO_SHORT, ContentType.IMAGE_POST]
        
        # Precompute common combinations
        warmup_count = 0
        for concept in common_concepts:
            for platform in platforms:
                for content_type in content_types:
                    # Simulate analysis
                    key = f"{concept}:{platform.value}:{content_type.value}"
                    self.cache_manager.set(
                        concept, 
                        platform.value,
                        content_type.value,
                        {'warmed': True}
                    )
                    warmup_count += 1
        
        print(f"  ‚úì Cache warmed with {warmup_count} common patterns")


def demo_performance_optimizer():
    """Demonstrate performance optimization"""
    print("PERFORMANCE OPTIMIZER DEMO")
    print("=" * 60)
    
    # Create optimizer
    optimizer = PerformanceOptimizer()
    
    # Warmup cache
    optimizer.warmup_cache()
    
    # Create test content
    from ..content_types import ContentPiece, ContentType, Platform
    
    test_contents = []
    for i in range(10):
        content = ContentPiece(
            content_type=ContentType.VIDEO_SHORT,
            platform=Platform.TIKTOK if i % 3 == 0 else Platform.INSTAGRAM
        )
        content.consciousness.coherence_level = 0.7 + (i % 3) * 0.1
        test_contents.append(content)
    
    # Test single optimization
    print("\n1Ô∏è‚É£ Single Content Optimization:")
    start = time.time()
    optimized = optimizer._optimize_single(test_contents[0])
    single_time = time.time() - start
    print(f"  Time: {single_time:.3f}s")
    print(f"  Engagement: {optimized.optimization.predicted_engagement:.1f}%")
    
    # Test batch optimization
    print("\n2Ô∏è‚É£ Batch Optimization (10 pieces):")
    start = time.time()
    optimized_batch = optimizer.optimize_batch(test_contents)
    batch_time = time.time() - start
    print(f"  Total time: {batch_time:.3f}s")
    print(f"  Average per piece: {batch_time/len(test_contents):.3f}s")
    print(f"  Speedup: {(single_time * len(test_contents)) / batch_time:.1f}x")
    
    # Show cache stats
    print("\n3Ô∏è‚É£ Performance Stats:")
    stats = optimizer.get_performance_stats()
    print(f"  Cache hit rate: {stats['cache']['hit_rate']:.1%}")
    print(f"  Cache size: {stats['cache']['size']}/{stats['cache']['max_size']}")
    print(f"  Parallel workers: {stats['threading']['max_workers']}")
    
    # Test with cache hits
    print("\n4Ô∏è‚É£ Cached Performance:")
    start = time.time()
    # Re-optimize same content (should hit cache)
    reoptimized = optimizer.optimize_batch(test_contents[:5])
    cached_time = time.time() - start
    print(f"  Time with cache: {cached_time:.3f}s")
    print(f"  Speedup from cache: {batch_time/2 / cached_time:.1f}x")
    
    print("\n‚úÖ Performance optimizer demo complete!")
    print(f"‚ö° All optimizations completed in <1s per piece!")


if __name__ == "__main__":
    demo_performance_optimizer()