#!/usr/bin/env python3
"""
CORTEX-A Prototype Implementation
=================================
Milestone CTX.1.2: CORTEX Planner and Basic Compute Agent Interaction

This prototype demonstrates:
1. CORTEX Planner (Leader Node) implementation
2. Expert Compute Agent template
3. Task distribution and parallel execution
4. Result aggregation
"""

import asyncio
import json
import time
import uuid
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, List, Any, Optional, Tuple, Callable
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import numpy as np
from datetime import datetime
import hashlib


# ============================================================================
# Core Data Structures
# ============================================================================

class ExpertiseType(Enum):
    """Types of expert agents available"""
    VECTOR_ANALYTICS = "vector_analytics"
    FRACTAL_ANALYSIS = "fractal_analysis"
    CSS_OPTIMIZATION = "css_optimization"
    COHERENCE_ANALYSIS = "coherence_analysis"
    SYSTEM_DYNAMICS = "system_dynamics"
    PATTERN_MATCHING = "pattern_matching"


class TaskStatus(Enum):
    """Task execution status"""
    PENDING = "pending"
    ASSIGNED = "assigned"
    EXECUTING = "executing"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class AgentProfile:
    """Expert agent profile and capabilities"""
    agent_id: str
    expertise_type: ExpertiseType
    skill_level: str = "undergraduate"  # undergraduate, graduate, professional, executive
    instantiation_time: float = field(default_factory=time.time)
    tasks_completed: int = 0
    performance_score: float = 0.0
    knowledge_template: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        if not self.knowledge_template:
            self.knowledge_template = self._load_default_knowledge()
    
    def _load_default_knowledge(self) -> Dict[str, Any]:
        """Load default knowledge template based on expertise"""
        return {
            "theory": f"Foundational theory for {self.expertise_type.value}",
            "heuristics": [
                f"IF condition_a THEN action_1",
                f"PREFER efficiency OVER accuracy WHEN time_constrained"
            ],
            "examples": [],
            "benchmarks": {
                "latency_ms": 10,
                "accuracy": 0.95,
                "memory_mb": 100
            }
        }


@dataclass
class CortexTask:
    """Task to be executed by compute agents"""
    task_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    task_type: str = ""
    query_segment: Dict[str, Any] = field(default_factory=dict)
    required_expertise: ExpertiseType = ExpertiseType.VECTOR_ANALYTICS
    priority: int = 5
    status: TaskStatus = TaskStatus.PENDING
    assigned_agent: Optional[str] = None
    result: Optional[Any] = None
    error: Optional[str] = None
    metrics: Dict[str, float] = field(default_factory=dict)


@dataclass
class ExecutionPlan:
    """Query execution plan"""
    plan_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    query_ast: Dict[str, Any] = field(default_factory=dict)
    tasks: List[CortexTask] = field(default_factory=list)
    parallelism_degree: int = 1
    estimated_cost: float = 0.0
    actual_cost: float = 0.0


# ============================================================================
# Expert Compute Agent Base Class
# ============================================================================

class ExpertComputeAgent(ABC):
    """Base class for all expert compute agents"""
    
    def __init__(self, profile: AgentProfile):
        self.profile = profile
        self.current_task: Optional[CortexTask] = None
        self._performance_history: List[float] = []
        
    @abstractmethod
    async def execute_task(self, task: CortexTask) -> Dict[str, Any]:
        """Execute assigned task - must be implemented by subclasses"""
        pass
    
    async def process_task(self, task: CortexTask) -> CortexTask:
        """Process a task and update metrics"""
        start_time = time.time()
        task.status = TaskStatus.EXECUTING
        task.assigned_agent = self.profile.agent_id
        
        try:
            # Execute the task
            result = await self.execute_task(task)
            
            # Update task
            task.result = result
            task.status = TaskStatus.COMPLETED
            task.metrics['execution_time_ms'] = (time.time() - start_time) * 1000
            
            # Update agent metrics
            self.profile.tasks_completed += 1
            self._update_performance(task.metrics['execution_time_ms'])
            
        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.metrics['execution_time_ms'] = (time.time() - start_time) * 1000
            
        return task
    
    def _update_performance(self, execution_time_ms: float):
        """Update agent performance metrics"""
        self._performance_history.append(execution_time_ms)
        if len(self._performance_history) > 100:
            self._performance_history.pop(0)
        
        # Calculate performance score (lower time = higher score)
        avg_time = np.mean(self._performance_history)
        target_time = self.profile.knowledge_template['benchmarks']['latency_ms']
        self.profile.performance_score = min(100, (target_time / avg_time) * 100)
        
        # Check for skill level progression
        self._check_skill_progression()
    
    def _check_skill_progression(self):
        """Check if agent should progress to next skill level"""
        progression_thresholds = {
            "undergraduate": (10, 80),    # 10 tasks, 80% performance
            "graduate": (50, 85),          # 50 tasks, 85% performance
            "professional": (200, 90),     # 200 tasks, 90% performance
        }
        
        if self.profile.skill_level in progression_thresholds:
            tasks_req, perf_req = progression_thresholds[self.profile.skill_level]
            if (self.profile.tasks_completed >= tasks_req and 
                self.profile.performance_score >= perf_req):
                # Progress to next level
                levels = ["undergraduate", "graduate", "professional", "executive"]
                current_idx = levels.index(self.profile.skill_level)
                if current_idx < len(levels) - 1:
                    self.profile.skill_level = levels[current_idx + 1]
                    print(f"üéì Agent {self.profile.agent_id} promoted to {self.profile.skill_level}!")


# ============================================================================
# Specialized Expert Agent Implementations
# ============================================================================

class VectorAnalyticsAgent(ExpertComputeAgent):
    """Expert in vector operations and analytics"""
    
    async def execute_task(self, task: CortexTask) -> Dict[str, Any]:
        """Execute vector analytics task"""
        # Simulate vector computation
        await asyncio.sleep(0.01)  # Simulate computation time
        
        # Extract vectors from task
        vectors = task.query_segment.get('vectors', [])
        operation = task.query_segment.get('operation', 'similarity')
        
        if operation == 'similarity':
            # Compute cosine similarity matrix
            if len(vectors) >= 2:
                similarity = np.random.random((len(vectors), len(vectors)))
                np.fill_diagonal(similarity, 1.0)
                result = {
                    'similarity_matrix': similarity.tolist(),
                    'max_similarity': float(np.max(similarity[similarity < 1.0])),
                    'avg_similarity': float(np.mean(similarity[similarity < 1.0]))
                }
            else:
                result = {'error': 'Insufficient vectors for similarity computation'}
        
        elif operation == 'clustering':
            # Simulate clustering
            n_clusters = task.query_segment.get('n_clusters', 3)
            cluster_assignments = np.random.randint(0, n_clusters, len(vectors))
            result = {
                'cluster_assignments': cluster_assignments.tolist(),
                'n_clusters': n_clusters,
                'inertia': np.random.random() * 100
            }
        
        else:
            result = {'error': f'Unknown operation: {operation}'}
        
        return result


class FractalAnalysisAgent(ExpertComputeAgent):
    """Expert in fractal dimension and pattern analysis"""
    
    async def execute_task(self, task: CortexTask) -> Dict[str, Any]:
        """Execute fractal analysis task"""
        await asyncio.sleep(0.015)  # Slightly more complex computation
        
        # Extract data from task
        entity_data = task.query_segment.get('entity_data', {})
        analysis_type = task.query_segment.get('analysis_type', 'dimension')
        
        if analysis_type == 'dimension':
            # Calculate fractal dimension
            fractal_dim = 1.0 + np.random.random() * 0.8  # Between 1.0 and 1.8
            lacunarity = np.random.random() * 2.0
            
            result = {
                'entity_id': entity_data.get('id', 'unknown'),
                'fractal_dimension': float(fractal_dim),
                'lacunarity': float(lacunarity),
                'complexity_score': float(fractal_dim * lacunarity)
            }
        
        elif analysis_type == 'pattern_match':
            # Pattern matching
            target_pattern = task.query_segment.get('target_pattern', {})
            match_score = np.random.random()
            
            result = {
                'entity_id': entity_data.get('id', 'unknown'),
                'pattern_match_score': float(match_score),
                'matched': match_score > 0.7
            }
        
        else:
            result = {'error': f'Unknown analysis type: {analysis_type}'}
        
        return result


class CSSOptimizationAgent(ExpertComputeAgent):
    """Expert in Cognitive State Space optimization"""
    
    async def execute_task(self, task: CortexTask) -> Dict[str, Any]:
        """Execute CSS optimization task"""
        await asyncio.sleep(0.02)  # CSS calculations are complex
        
        # Extract CSS field data
        css_field = task.query_segment.get('css_field', {})
        optimization_target = task.query_segment.get('target', 'coherence')
        
        if optimization_target == 'coherence':
            # Optimize for coherence
            current_coherence = css_field.get('coherence', 0.5)
            optimized_coherence = min(1.0, current_coherence + np.random.random() * 0.2)
            
            result = {
                'entity_id': css_field.get('entity_id', 'unknown'),
                'original_coherence': float(current_coherence),
                'optimized_coherence': float(optimized_coherence),
                'improvement': float(optimized_coherence - current_coherence),
                'optimization_steps': [
                    {'step': 1, 'action': 'phase_alignment', 'impact': 0.05},
                    {'step': 2, 'action': 'frequency_tuning', 'impact': 0.10},
                    {'step': 3, 'action': 'amplitude_normalization', 'impact': 0.05}
                ]
            }
        
        elif optimization_target == 'distance':
            # Minimize CSS distance to target
            current_distance = css_field.get('distance_to_optimal', 1.0)
            optimized_distance = max(0.0, current_distance - np.random.random() * 0.3)
            
            result = {
                'entity_id': css_field.get('entity_id', 'unknown'),
                'original_distance': float(current_distance),
                'optimized_distance': float(optimized_distance),
                'reduction': float(current_distance - optimized_distance)
            }
        
        else:
            result = {'error': f'Unknown optimization target: {optimization_target}'}
        
        return result


# ============================================================================
# Agent Registry and Factory
# ============================================================================

class AgentRegistry:
    """Registry for managing expert agents"""
    
    def __init__(self):
        self.registered_agents: Dict[str, ExpertComputeAgent] = {}
        self.agent_pools: Dict[ExpertiseType, List[str]] = {
            exp_type: [] for exp_type in ExpertiseType
        }
        self.agent_classes = {
            ExpertiseType.VECTOR_ANALYTICS: VectorAnalyticsAgent,
            ExpertiseType.FRACTAL_ANALYSIS: FractalAnalysisAgent,
            ExpertiseType.CSS_OPTIMIZATION: CSSOptimizationAgent,
        }
    
    def instantiate_agent(self, expertise_type: ExpertiseType) -> str:
        """Instantiate a new expert agent"""
        # Create agent profile
        agent_id = f"{expertise_type.value}_{uuid.uuid4().hex[:8]}"
        profile = AgentProfile(
            agent_id=agent_id,
            expertise_type=expertise_type
        )
        
        # Create agent instance
        agent_class = self.agent_classes.get(expertise_type, ExpertComputeAgent)
        agent = agent_class(profile)
        
        # Register agent
        self.registered_agents[agent_id] = agent
        self.agent_pools[expertise_type].append(agent_id)
        
        print(f"ü§ñ Instantiated {expertise_type.value} agent: {agent_id}")
        return agent_id
    
    def get_or_instantiate(self, expertise_type: ExpertiseType) -> ExpertComputeAgent:
        """Get an available agent or instantiate a new one"""
        # Check for available agents
        available_agents = [
            agent_id for agent_id in self.agent_pools[expertise_type]
            if self.registered_agents[agent_id].current_task is None
        ]
        
        if available_agents:
            # Use existing agent with best performance
            best_agent_id = max(
                available_agents,
                key=lambda aid: self.registered_agents[aid].profile.performance_score
            )
            return self.registered_agents[best_agent_id]
        else:
            # Instantiate new agent
            agent_id = self.instantiate_agent(expertise_type)
            return self.registered_agents[agent_id]
    
    def get_agent(self, agent_id: str) -> Optional[ExpertComputeAgent]:
        """Get agent by ID"""
        return self.registered_agents.get(agent_id)


# ============================================================================
# Query Parser and Optimizer
# ============================================================================

class CQLParser:
    """Simple CQL (CORTEX Query Language) parser"""
    
    def parse(self, cql_query: str) -> Dict[str, Any]:
        """Parse CQL query into AST"""
        # This is a simplified parser for demonstration
        ast = {
            'type': 'SELECT',
            'projections': [],
            'from': '',
            'where': [],
            'distribute_by': None,
            'parallel': None
        }
        
        # Extract key components (simplified)
        lines = cql_query.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('SELECT'):
                ast['projections'] = [p.strip() for p in line[6:].split(',')]
            elif line.startswith('FROM'):
                ast['from'] = line[4:].strip()
            elif line.startswith('WHERE'):
                ast['where'].append(line[5:].strip())
            elif line.startswith('DISTRIBUTE BY'):
                ast['distribute_by'] = line[13:].strip()
            elif line.startswith('PARALLEL'):
                ast['parallel'] = line[8:].strip()
        
        return ast


class CORTEXQueryOptimizer:
    """Query optimizer for parallel execution"""
    
    def optimize(self, query_ast: Dict[str, Any]) -> ExecutionPlan:
        """Generate optimized execution plan"""
        plan = ExecutionPlan(query_ast=query_ast)
        
        # Analyze query to determine required expertise
        required_expertise = self._identify_required_expertise(query_ast)
        
        # Create tasks based on query
        if 'fractal' in str(query_ast).lower():
            # Fractal analysis tasks
            for i in range(3):  # Simulate multiple entities
                task = CortexTask(
                    task_type='fractal_analysis',
                    query_segment={
                        'entity_data': {'id': f'entity_{i}'},
                        'analysis_type': 'dimension'
                    },
                    required_expertise=ExpertiseType.FRACTAL_ANALYSIS
                )
                plan.tasks.append(task)
        
        if 'css' in str(query_ast).lower():
            # CSS optimization tasks
            for i in range(2):
                task = CortexTask(
                    task_type='css_optimization',
                    query_segment={
                        'css_field': {'entity_id': f'entity_{i}', 'coherence': 0.6},
                        'target': 'coherence'
                    },
                    required_expertise=ExpertiseType.CSS_OPTIMIZATION
                )
                plan.tasks.append(task)
        
        # Default: vector analytics
        if not plan.tasks:
            task = CortexTask(
                task_type='vector_analytics',
                query_segment={
                    'vectors': [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                    'operation': 'similarity'
                },
                required_expertise=ExpertiseType.VECTOR_ANALYTICS
            )
            plan.tasks.append(task)
        
        plan.parallelism_degree = len(set(t.required_expertise for t in plan.tasks))
        plan.estimated_cost = len(plan.tasks) * 0.01  # Simplified cost model
        
        return plan
    
    def _identify_required_expertise(self, query_ast: Dict[str, Any]) -> List[ExpertiseType]:
        """Identify required expertise types from query"""
        required = []
        query_text = str(query_ast).lower()
        
        if 'vector' in query_text or 'similarity' in query_text:
            required.append(ExpertiseType.VECTOR_ANALYTICS)
        if 'fractal' in query_text or 'dimension' in query_text:
            required.append(ExpertiseType.FRACTAL_ANALYSIS)
        if 'css' in query_text or 'coherence' in query_text:
            required.append(ExpertiseType.CSS_OPTIMIZATION)
        
        return required if required else [ExpertiseType.VECTOR_ANALYTICS]


# ============================================================================
# CORTEX Planner (Leader Node)
# ============================================================================

class CORTEXPlanner:
    """
    Leader node for query planning and task distribution
    """
    
    def __init__(self):
        self.agent_registry = AgentRegistry()
        self.query_parser = CQLParser()
        self.query_optimizer = CORTEXQueryOptimizer()
        self.execution_history: List[Dict[str, Any]] = []
        
        # Pre-instantiate some agents
        self._initialize_agent_pool()
    
    def _initialize_agent_pool(self):
        """Pre-instantiate a small pool of agents"""
        print("üöÄ Initializing CORTEX-A agent pool...")
        for expertise_type in [ExpertiseType.VECTOR_ANALYTICS, 
                              ExpertiseType.FRACTAL_ANALYSIS,
                              ExpertiseType.CSS_OPTIMIZATION]:
            self.agent_registry.instantiate_agent(expertise_type)
    
    async def process_query(self, cql_query: str) -> Dict[str, Any]:
        """
        Process a CQL query through the full pipeline
        """
        start_time = time.time()
        print(f"\nüìä Processing query: {cql_query[:50]}...")
        
        # 1. Parse query
        query_ast = self.query_parser.parse(cql_query)
        
        # 2. Generate execution plan
        plan = self.query_optimizer.optimize(query_ast)
        print(f"üìã Execution plan: {len(plan.tasks)} tasks, {plan.parallelism_degree} parallel streams")
        
        # 3. Assign agents to tasks
        agent_assignments = {}
        for task in plan.tasks:
            agent = self.agent_registry.get_or_instantiate(task.required_expertise)
            agent_assignments[task.task_id] = agent
            print(f"  ‚Ü≥ Task {task.task_id[:8]} assigned to {agent.profile.agent_id}")
        
        # 4. Execute tasks in parallel
        results = await self._execute_parallel(plan.tasks, agent_assignments)
        
        # 5. Aggregate results
        aggregated_result = self._aggregate_results(results, plan)
        
        # 6. Record execution metrics
        execution_time = time.time() - start_time
        plan.actual_cost = execution_time
        
        execution_record = {
            'query': cql_query,
            'plan_id': plan.plan_id,
            'execution_time_ms': execution_time * 1000,
            'tasks_executed': len(plan.tasks),
            'tasks_succeeded': sum(1 for r in results if r.status == TaskStatus.COMPLETED),
            'timestamp': datetime.now().isoformat()
        }
        self.execution_history.append(execution_record)
        
        print(f"‚úÖ Query completed in {execution_time*1000:.1f}ms")
        
        return {
            'status': 'success',
            'plan_id': plan.plan_id,
            'result': aggregated_result,
            'metrics': execution_record
        }
    
    async def _execute_parallel(self, 
                               tasks: List[CortexTask], 
                               agent_assignments: Dict[str, ExpertComputeAgent]) -> List[CortexTask]:
        """Execute tasks in parallel using assigned agents"""
        # Create coroutines for all tasks
        coroutines = [
            agent_assignments[task.task_id].process_task(task)
            for task in tasks
        ]
        
        # Execute all tasks concurrently
        completed_tasks = await asyncio.gather(*coroutines)
        
        return completed_tasks
    
    def _aggregate_results(self, completed_tasks: List[CortexTask], plan: ExecutionPlan) -> Dict[str, Any]:
        """Aggregate results from completed tasks"""
        aggregated = {
            'total_tasks': len(completed_tasks),
            'successful_tasks': sum(1 for t in completed_tasks if t.status == TaskStatus.COMPLETED),
            'failed_tasks': sum(1 for t in completed_tasks if t.status == TaskStatus.FAILED),
            'results_by_type': {},
            'aggregate_metrics': {}
        }
        
        # Group results by task type
        for task in completed_tasks:
            if task.status == TaskStatus.COMPLETED:
                task_type = task.task_type
                if task_type not in aggregated['results_by_type']:
                    aggregated['results_by_type'][task_type] = []
                aggregated['results_by_type'][task_type].append(task.result)
        
        # Calculate aggregate metrics
        all_execution_times = [t.metrics.get('execution_time_ms', 0) for t in completed_tasks]
        if all_execution_times:
            aggregated['aggregate_metrics'] = {
                'avg_execution_time_ms': np.mean(all_execution_times),
                'max_execution_time_ms': np.max(all_execution_times),
                'min_execution_time_ms': np.min(all_execution_times),
                'total_execution_time_ms': np.sum(all_execution_times)
            }
        
        return aggregated
    
    def get_agent_statistics(self) -> Dict[str, Any]:
        """Get statistics about agent pool"""
        stats = {
            'total_agents': len(self.agent_registry.registered_agents),
            'agents_by_expertise': {},
            'agents_by_skill_level': {},
            'top_performers': []
        }
        
        # Count by expertise
        for exp_type in ExpertiseType:
            stats['agents_by_expertise'][exp_type.value] = len(self.agent_registry.agent_pools[exp_type])
        
        # Count by skill level
        skill_counts = {}
        for agent in self.agent_registry.registered_agents.values():
            skill = agent.profile.skill_level
            skill_counts[skill] = skill_counts.get(skill, 0) + 1
        stats['agents_by_skill_level'] = skill_counts
        
        # Top performers
        all_agents = list(self.agent_registry.registered_agents.values())
        top_agents = sorted(all_agents, key=lambda a: a.profile.performance_score, reverse=True)[:5]
        stats['top_performers'] = [
            {
                'agent_id': a.profile.agent_id,
                'expertise': a.profile.expertise_type.value,
                'skill_level': a.profile.skill_level,
                'performance_score': a.profile.performance_score,
                'tasks_completed': a.profile.tasks_completed
            }
            for a in top_agents
        ]
        
        return stats


# ============================================================================
# Demo and Testing
# ============================================================================

async def demo_cortex_a():
    """Demonstrate CORTEX-A functionality"""
    print("=" * 60)
    print("CORTEX-A PROTOTYPE DEMONSTRATION")
    print("=" * 60)
    
    # Initialize CORTEX Planner
    planner = CORTEXPlanner()
    
    # Test Query 1: Fractal Analysis
    print("\nüìù Test Query 1: Fractal Dimension Analysis")
    cql_query_1 = """
    SELECT 
        entity_id,
        fractal_dimension,
        lacunarity
    FROM 
        fmo_entities
    WHERE 
        tcs_archetype = 'Decay'
    PARALLEL 
        USING expert_agents('fractal_analysis')
    """
    
    result_1 = await planner.process_query(cql_query_1)
    print(f"\nResults: {json.dumps(result_1['result'], indent=2)}")
    
    # Test Query 2: CSS Optimization
    print("\nüìù Test Query 2: CSS Field Optimization")
    cql_query_2 = """
    SELECT 
        entity_id,
        css_coherence,
        optimization_steps
    FROM 
        css_fields
    WHERE 
        coherence < 0.7
    PARALLEL 
        USING expert_agents('css_optimization')
    """
    
    result_2 = await planner.process_query(cql_query_2)
    print(f"\nResults: {json.dumps(result_2['result'], indent=2)}")
    
    # Test Query 3: Mixed expertise
    print("\nüìù Test Query 3: Combined Analysis")
    cql_query_3 = """
    SELECT 
        entity_id,
        fractal_dimension,
        css_coherence,
        vector_similarity
    FROM 
        fmo_entities
    PARALLEL 
        USING expert_agents('fractal_analysis', 'css_optimization', 'vector_analytics')
    """
    
    result_3 = await planner.process_query(cql_query_3)
    
    # Show agent statistics
    print("\nüìä Agent Pool Statistics")
    stats = planner.get_agent_statistics()
    print(f"Total agents: {stats['total_agents']}")
    print(f"Agents by expertise: {stats['agents_by_expertise']}")
    print(f"Agents by skill level: {stats['agents_by_skill_level']}")
    print("\nTop Performers:")
    for agent in stats['top_performers']:
        print(f"  ‚Ä¢ {agent['agent_id']}: {agent['performance_score']:.1f} score, "
              f"{agent['tasks_completed']} tasks, {agent['skill_level']} level")
    
    # Show execution history
    print("\nüìú Execution History")
    for record in planner.execution_history[-3:]:
        print(f"  ‚Ä¢ Query at {record['timestamp']}: "
              f"{record['execution_time_ms']:.1f}ms, "
              f"{record['tasks_succeeded']}/{record['tasks_executed']} succeeded")


async def stress_test_cortex_a():
    """Stress test with multiple parallel queries"""
    print("\n" + "=" * 60)
    print("CORTEX-A STRESS TEST")
    print("=" * 60)
    
    planner = CORTEXPlanner()
    
    # Generate 10 random queries
    queries = []
    for i in range(10):
        query_type = np.random.choice(['fractal', 'css', 'vector'])
        if query_type == 'fractal':
            query = f"SELECT fractal_dimension FROM entities WHERE id = 'test_{i}'"
        elif query_type == 'css':
            query = f"SELECT css_coherence FROM fields WHERE entity = 'test_{i}'"
        else:
            query = f"SELECT vector_similarity FROM vectors WHERE batch = '{i}'"
        queries.append(query)
    
    print(f"üöÄ Executing {len(queries)} queries in parallel...")
    start_time = time.time()
    
    # Execute all queries concurrently
    results = await asyncio.gather(*[planner.process_query(q) for q in queries])
    
    total_time = time.time() - start_time
    successful = sum(1 for r in results if r['status'] == 'success')
    
    print(f"\n‚úÖ Stress test complete:")
    print(f"  ‚Ä¢ Total queries: {len(queries)}")
    print(f"  ‚Ä¢ Successful: {successful}")
    print(f"  ‚Ä¢ Total time: {total_time*1000:.1f}ms")
    print(f"  ‚Ä¢ Avg time per query: {total_time*1000/len(queries):.1f}ms")
    print(f"  ‚Ä¢ Queries per second: {len(queries)/total_time:.1f}")


# ============================================================================
# Main Entry Point
# ============================================================================

if __name__ == "__main__":
    # Run demonstrations
    asyncio.run(demo_cortex_a())
    asyncio.run(stress_test_cortex_a())
    
    print("\n‚ú® CORTEX-A Prototype demonstration complete!")
    print("Next steps: Implement CORTEX_DataStore and CQL parser enhancements")